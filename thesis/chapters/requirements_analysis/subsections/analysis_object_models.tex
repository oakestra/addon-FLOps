\subsection{Analysis Object Models}
% TODO Paraphraze!
To increase the understanding of the underlying structure of the proposed
system UML class diagrams are used to visualize the main components and
their relationships [BD09].
The analysis model represents the system under development from the userâ€™s point of view. The
"analysis object model is a part of the analysis model and focuses on the individual concepts that
are manipulated by the system, their properties and their relationships. The analysis object
model, depicted with UML class diagrams, includes classes, attributes, and operations. The
analysis object model is a visual dictionary of the main concepts visible to the user."

FLOps covers various different aspects that need to be understood individually to be able to comprehend their need for the whole picture.



\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{uml_analysis_object_model_core.png}
    \caption{FLOps Core UML Analysis Object Model}
    \label{fig:uml_core_analysis_object_model}
\end{figure}

Figure \ref{fig:uml_core_analysis_object_model} shows the core FLOps UML Analysis Object Model.
Following models will explain more concrete details about individual core components. 
The main workflow is represented and grouped via a FLOps Project.
Such a project links all necessary FL and ML/DevOps components together to power one entire FL user request.
A project contains information about the user who requested it, the target platforms that should be supported (e.g. ARM/AMD) or what steps FLOps should perform after training.
If no steps are specified the FLOps project counts as completed after training.
Available post-training steps include building a containerized image for the trained model 
and deploying an inference server to serve the trained model.
The ML Model Flavor is an indicator to tell FLOps what ML framework to expect and to work with.
Examples include Keras, Sklearn, or Pytorch.
Each project is associated with exactly one ML Code Repository.
This repository can be owned by the user or be a public one.
Thus, multiple users can reuse the same repository and each user can create multiple FLOps projects per repository.
These properties are based on the SLA from the user request. 

FLOps uses the concepts of Applications and Services to manage dependent components and concepts.
Each app can have multiple services.
Services are bound to parent apps, they cannot exist on their own.
Apps and services can and have to be created via the orchestrator as usable components.
Applications themselves are collectors of information and metadata, they do not run or contain any executable code, images, or similar.
Services are the computational components that can be deployed and undeployed.
This split is based on Oakestra's applications and services.
The two main FLOps app types are project-based apps and customer-facing ones.
The Observatory app is a customer-facing app.
There is exactly one observatory app for each user.
Users can have multiple projects.
The observatory hosts the tracking server and project observer services.
The tracking server service is used to track the projects and individual FL experiments.
It hosts the GUI. 
(It utilizes the MLFlow tracking server mentioned in \ref{subsection:mlflow}.)
When users request/start a new project the observatory is created with all its components in case it did not yet exist.
Users can request access to the GUI/tracking-server independently from a project.
A Project Observer service is used to gather and show information or updates regarding the project status to the user.
The project observer informs the user if there are any issues during the project live time, such as dependency issues during the containerizated image builds.
There is one Project Observer per project to improve readability and comprehension.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{uml_analysis_object_model_repo.png}
    \caption{FLOps ML Code Repository UML Analysis Object Model}
    \label{fig:uml_repo_analysis_object_model}
\end{figure}

Figure \ref{fig:uml_repo_analysis_object_model} shows additional details of the ML Code Repositories from the core model.
Users can provide a link to ML code repositories for FLOps to augment and train.
For this to be possible and straightforward the repository needs to fulfill the following structural requirements.
The repository needs to have a dedicated file that lists all necessary dependencies to train its model.
Theoretically it should be possible to extract these requirements dynamically by inspecting the code.
However, this is a complex and error prone endeavour.
To avoid this issues users should provide the dependencies they used for training.
We recommend to run the training locally on some exemplary or mock data and record the dependencies via MLflow's auto logging functionality.
This is a possible and easy approach to get a suitable dependency file.
Note that this is not a guarantee that the dependencies will be compatible, because MLflow's dependency logging can be erroneous.
Before providing the dependency file to FLOps we recommend to make sure the dependencies are sufficient and compatible.

For FLOps to augment the ML code and utilize is properly FLOps excepts the repository to implement a model manager and data manger.
The model manager is the interface to access the model and its data and parameters.
It further allows to train and evaluate the model.
It calls its linked data manager to prepare the data and retrieve it once it is ready.
The data itself should not be part of the repository.
The prepare data method will call a FLOps method that will be added during FL augmentation.
The user has to define in prepareData how to preprocess the retrieved data for individual training.

Both managers have an abstract parent class that users can import during implementation for guidelines.
These templates can be found as part of the FLOps Utils pip package \cite{flops_utils_pip}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{uml_analysis_object_model_project.png}
    \caption{FLOps Project UML Analysis Object Model}
    \label{fig:uml_project_analysis_object_model}
\end{figure}

Figure \ref{fig:uml_project_analysis_object_model} shows further details about a FLOps project's contents.
Users can customize their projects via the SLA that is included in their API requests.
One possible customization is to specify resource constraints such as memory or storage.
Users can customize the FL training by changing the project's training configuration.
The same ML repository can be trained differently depending on these configurations.
This configuration includes a mode that tells FLOps to perform different types of FL if applicable.
Currently FLOps supports classic and (clustered) HFL.
Only training data will be used that matches the provided data tags.
The training rounds configure the number of training and evaluation rounds that each learner performs.
The training cycles are only used for HFL.
The training rounds mean the number of training rounds on performed on each learner per cycle.
A training cycle stands for the number of training rounds between the root and cluster aggregators, which can be seen as aggregator and learners, thus classic FL.
For example if the user requests 3 cycles and 5 rounds this means that the learners will train 5 rounds per cycle for 3 cycles.
In total each learner will train for 15 rounds during the entire project runtime.
The depicted attributes are only a supset of currently available and possible configurations.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{uml_analysis_object_model_project_services.png}
    \caption{FLOps Project Services UML Analysis Object Model}
    \label{fig:uml_project_services_analysis_object_model}
\end{figure}

The core figure \ref{fig:uml_core_analysis_object_model} only alluded that a project consists out of several services and depicted only the project observer.
Figure \ref{fig:uml_project_services_analysis_object_model} expands upon this and shows important project services and their relationships.
There are three main project services.
The FL Image Builder is a service that builds containerized images.
It can build the FL augmented images for the learner and aggregator as well as the inference server of the trained model.
This distinction is made via the buildPlans.
The builder clones the ML repository, handles and checks the provided dependencies, builds the images and pushes them to an image registry.
During and and the end of the builder operation the service notifies other components including the project observer about its progress, current state and potential errors.

The FL Aggregator manages the FL training loop and holds the global Model and strategy for training.
It starts its internal FL server for learners to register for training.
The aggregator starts and terminates learning rounds and cycles
It logs results like metrics or the final trained model via the tracking server.
Similarly to the builder it notifies other components during runtime about its progress and errors.

The aggregator and learners utilize the code provided in the user's ML code repositories.
They have direct access to the model and data managers.
Both are injected via the image builder.

The FL learners are project services that perform the FL training on local data.
They fetch locally stored data, connect to the aggregator, and perform FL activities such as training.
The learner uses the code found in the model and data managers and wrap itself around their implemented interface methods.
As a results users do not need to implement the FL (boilerplate) code themselves.
Therefore, a getParameters methods of a learner uses the getParameters method described in the user's ML repository with additional logic around it.
Learners also notify other components about their progress or failures.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth]{uml_analysis_object_model_aggregators.png}
    \caption{FLOps Aggregator Types UML Analysis Object Model}
    \label{fig:uml_project_aggregators_analysis_object_model}
\end{figure}

Figure \ref{fig:uml_project_aggregators_analysis_object_model} shows the simplified relation between different FLOps aggregator types.
Because FLOps support classic and hierarchical FL it needs to support different aggregator types.
For conventional FL the classic aggregators are used, whereas for HFL one root aggregator is created with one cluster aggregator per cluster available in the orchestrator.
The root orchestrator sees cluster orchestrators as plain learners.
A cluster aggregator is a hybrid between an aggregator and a learner.