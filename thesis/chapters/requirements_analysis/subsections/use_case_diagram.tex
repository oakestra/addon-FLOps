\subsection{Use Case Model}

UML use case diagrams visualize the use of all significant available functions of a system from the user's perspective.
They are based on the functional requirements.
This means that every function, whether directly triggered by the user or an internal system function, that leads to observable changes and results for the user is depicted.
Use case diagrams aim to showcase available and consequential functionality as seen by the user in a compact representation. \cite{book:bruegge}

\begin{figure}[p]
    \begin{adjustwidth}{-0.1\paperwidth}{-0.1\paperwidth}
        \centering
        \includegraphics[width=0.9\paperwidth]{uml_use_case_diagram.png}
        \caption{FLOps UML Use Case Diagram}
        \label{fig:uml_use_case_diagram}
    \end{adjustwidth}
\end{figure}

Figure \ref{fig:uml_use_case_diagram} shows the Use Case diagram for FLOps.
The white use cases represent the functionalities the external users can directly trigger.
The grey use cases are internal system actions that are directly visible to users or lead to visible results.
They get triggered as a result of user actions.
For example, the user knows that FLOps is performing FL training by inspecting different provided outlets, such as the GUI.
FLOps tracks the training progress and results.
These logged artifacts become incrementally visible to the user who inspects the GUI.
Thus, the user knows that FLOps is currently performing FL training and logging.
Use cases inside the GUI boundary are directly accessible via the GUI. 
The same applies to the API boundary.
Other tasks are executed and accessible via FLOps combined with its orchestrator.
Use cases that involve developing or modifying FLOps itself are not explicitly portrayed.
The depicted User actor represents end users of varying FL expertise.
This actor includes FL developers and researchers.
The core use case is starting an FL project.
This activity starts a chain of events, such as building an FL-enabled container image, creating and deploying the learners and aggregator(s), and performing the FL training.
During training, FLOps tracks the model and system metrics, which the user can monitor and evaluate in the GUI.
After training, the model can be containerized and deployed as an inference server.
The user can access this trained model and request services from its inference server.
