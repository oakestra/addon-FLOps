\section{Current Status, Limitations \& Future Work}

Table \ref{table:status_functional_reqs} depicts how well the current FLOps implementation fulfills its functional requirements.
We count FR-1.3 and FR-2 as MVP implemented because FLOps supports different FL scenarios, such as classic and clustered HFL, as well as various project configurations.
Multiple additional FL strategies, algorithms, and Flower configurations exist that can and should be analyzed and added to future FLOps versions to allow a broader range of FL capabilities.
FLOps currently supports Scikit-learn, PyTorch, and TensorFlow.
Other ML flavors can be easily added by extending the underlying minimal enum structure.
We regard FR-6's inference serving as MVP implemented because enabling inference serving was not a primary focus point of FLOps.
Instead, inference serving is FLOps's last post-training step.
Thus, we did not invest too much time into this feature.
It should be thoroughly tested and investigated to be seen as fully realized.
MLflow offers different ways of turning trained models into inference servers \cite{mlflow_inference_serving}.
Analyzing and comparing these variations and letting users decide how to create inference servers is a valid choice for future work.

% https://aneescraftsmanship.com/circle-symbols%E2%97%8B%E2%97%8F%E2%97%8D%E2%97%97%E2%97%94%E2%97%99%E2%A6%BF-in-latex/
\begin{itemize}
    \item [\faCircleO] \textbf{Not Implemented}: FLOps does not meet the requirement in its current form. 
	\item [\faDotCircleO] \textbf{Partially Implemented}: FLOps only partially meets the requirement.
	\item [\faArrowCircleRight] \textbf{Implemented MVP}: FLOps fulfills the requirement in a minimal viable way. Features can be further extended.
	\item [\faCircle] \textbf{Fully Implemented}: FLOps fully realizes the requirement.
\end{itemize}

\begin{figure}[p]
	\input{tables/conclusion_functional_reqs_status.tex}
	\input{tables/conclusion_nonfunctional_reqs_status.tex}	
\end{figure}


Table \ref{table:status_nonfunctional_reqs} shows the grade of fulfillment of nonfunctional requirements in the current FLOps version.
FLOps only partially realizes NFR-2.2.2.
During the development of FLOps, we had to introduce several minor changes and additions to Oakestra so that it could handle FLOps workflows.
The FLOps project structure follows Oakestra's application and service structure, which differs from that of other orchestrators like Kubernetes.
Due to the restricted time, we did not try to run FLOps via another orchestrator.
Therefore, we need to find out how straightforward using FLOps with other orchestrators is.
Nonetheless, FLOps communicates with Oakestra via decoupled APIs and SLAs.
Replacing or extending these interaction points to other orchestrators should be straightforward.
In addition, Jabok Kempter's work combining Oakestra and Kubernetes \cite{thesis:tum_jakob_kempter_kubernetes_oakestra} alludes that FLOps can run on Kubernetes as an Oakestra addon.

We marked NFR-3.1 as MVP implemented and NFR-3.2 as partially implemented because FLOps can run on monolithic and small multi-cluster setups with varying FL actors.
We have yet to try to run FLOps on a truly large scale, such as several hundred or thousand devices.
Therefore, we cannot indefinitely confirm that It can handle large-scale deployments.
Regarding availability, FLOps includes several mechanisms of communication, error and event handling.
However, if FLOps services or applications are modified or deleted by an external non-FLOps source, current FLOps is incapable of reacting accordingly.
We hope to change this once FLOps is connected to the new Oakestra event hooks \cite{thesis:tum_mahmoud} so it can respond to and receive these vital events and react accordingly.


\subsubsection{Implementation}
FLOps includes many pre-made and custom components that we linked and implemented from the grounds up.
We did so by using various state-of-the-art frameworks and tools.
Many of these tools we worked with for the very first time during this work and had no prior experience, training, or peer review in.
Thus, various aspects of the implementation might be utilizing these SOTA tools in a subpar way.
FLOps' codebase is a solo-man project that lacks any code review from other people or domain/tool experts.
To improve robustness and code-quality people with expertise in these domains should review the code and elevate it to follow the gold standards of these tools.

\subsubsection{Image Building}
FLOps uses a sophisticated image building architecture and processes yet the evaluations have shown that this aspect is taking up a significant portion of project run times.
To further improve the build times and shrink the final images more newer experimental solutions should be explored.
One way would be to replace the current Conda-Mamba solution with uv \cite{uv}.
Other tools worth exploring to slim down images are found here \cite{slim,dragonfly,nydus}.

\subsubsection{Security \& Privacy}
Security and privacy are foundational concerns of FL.
Our priority with FLOps was to create and verify its foundational architecture and components.
Due to the lack of access to proper certificates and to accelerate FLOps' development we omitted privacy and security concerns.
This includes the use of HTTP instead of HTTPS or the lack of supported FL security features such as secure aggregation.
This aspect is one of the most important for future work.
The good news are that Flower, the image registry, and local data management Apache suite all come with security features that simply need to be configured properly.

\subsubsection{Federated Learning via FLOps}
Classic and clustered HFL is already working via FLOps.
There are many other possible improvements that should be considered for future work.
Possible directions include exploring and adding FL native security and privacy mechanisms or extending the already available functionalities by adding more parameters and different algorithms.
FLOps so far did not focus on GPU workloads, which are straightforward to add via Flower.
In addition, FLOps should be tried out with ML frameworks that are specifically targeted for resource restricted edge and IoT devices.
These experiments should be evaluated on real edge devices such as Raspberry Pis and hybrid setups.

One major aspect that should be investigated is personalized FL.
Flower already supports PFL thus it should be straightforward to enable these features to FLOps.
Custom solutions only using FLOps are also possible.
For classic PFL after training the global model this model could be deployed on every learner and trained further for local use only and then used for inference serving.
The sidecar or multi-model PFL solution could look like this.
The global model would be trained as is but a personal model would also be trained concurrently and not shared or updated with other learners.
Once the training is done the local model could be turned into an inference server.
Hybrids between both are also possible.
Our reading contained multiple interesting PFL papers so we think this directions is very promising and worth working on.

\subsubsection{Complementary Components \& Integrations}
The FLOps project has to be currently cloned, configured slightly and launched to work with it.
FLOps is a collection of components and relies upon its orchestrator and is heavily supported by its CLI.
This CLI could be further improved to automate even more aspects of FLOps and its orchestrator dependency.
Ideally the CLI could be installed via pip and with a single command the entire needed dependencies, repositories and components of FLOps and its orchestrator would be installed and launched to make working with these tools as easy and quick as possible.
Realizing this goal is not hard because the CLI already has many necessary functionalities that simply needs to be expanded and combined.
Besides this FLOps should be properly integrated into Oakestra's new addon marketplace and augmented via its hooks to react to events.
Once this is realized FLOps will be even more responsive and easier for users to work with.

