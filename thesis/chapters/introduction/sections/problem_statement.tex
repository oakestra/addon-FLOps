% ~ Focus on (current) Problems with 
% (also keep an eye on the motivation page for ideas - "mirror")

\section{Problem Statement}

With great access to data comes great responsibility that can be easily exploited.
Many of the aforementioned machines are personal user devices or belong to
companies and organizations that handle customer or internal resources.
These devices store and handle sensitive private data.

In classical Machine Learning, data gets sent from client devices to a centralized server.
The collected data is used on the server to train ML models or perform inference serving.
This approach provides direct access to this sensitive data and the power to trace it back,
creating a breach of privacy. \cite{book:fl}

Governments and organizations have established laws and regulations to prohibit
potential abuse of sensitive data.
Examples include the European Parliament regulation to protect personal data \cite{eu_regulation}
or the California Consumer Privacy Act (CCPA) \cite{california_consumer_privacy_act}.
These restrictions also aim to allow cooperation between nations and organizations while protecting trade secrets.
However, some laws and regulations even prohibit sharing or moving data to other countries. \cite{book:fl}

Ignoring and no longer using this large amount of data would heavily limit current workflows
and further improvements for many data-dependent and data-hungry technologies.
In 2017, a team of Google researcher introduced Federated Learning (FL)
as one possible solution to utilize sensitive data.
Instead of collecting the data on a server and training ML models there.
In FL, the model training occurs directly on the client devices.
Afterward, the individually trained models get sent to the server,
which combines the collected models into a single global one.
This global model can then be distributed to the clients again for further training cycles.
Therefore, it enables training a shared global model on sensitive data
while keeping the sensitive data secure on the local client devices. \cite{paper:original_fl}

Many researchers are working on the topic of FL.
The majority in this field focuses on improving existing FL
components, strategies, and algorithms or inventing better ways of doing FL.
It is scarce to see work that focuses on the actual initial setup, deployment,
or improvement of the usability of FL.
We discuss this in greater detail in the dedicated background section 2.1.

Because FL is a relatively modern technique,
it lacks a sophisticated production-grade eco-system that includes
frameworks and libraries that improve ease of use by automation the setup and execution of FL.
As a result, contributing to the field of FL or reproducing findings is a task
ranging from non-trivial to improbable due to the lack of documented steps regarding setup,
deployment, management, and execution.

Instead of using a shared set of tools for bootstrapping to make progress on novel work more efficiently,
one needs to reinvent the wheel of setting up and managing oneâ€™s FL.
There is a significant lack of unity and automation in the realm of FL.
FL lacks the bare-bone tools to work on it efficiently,
not to mention more advanced techniques to increase productivity that
other domains have already been using for several years, such as modern DevOps practices.