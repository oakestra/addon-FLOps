% research has been focused on optimizing FL algos
% comming up with new algos
% optimizing bottlenecks
%
% briefly mention the following aspects to highlight that FL is a complex topic with lots of things people are working on
% "Client-Side Local Training" - Computation, Memory, Energy, Network
% mention Security/Privacy
% https://www.notion.so/oakestra-team/Chapter-10-Local-Training-Scalability-of-FL-Systems-c0f945e2593e48ea9bdbb71c1d94d091?pvs=4
%
% Lack of papers discussing how to set-up, manage, orchestrate FL in the first place
% rarely talk how they set up their experiments
% rarely mention what they use for FL or even for ML
% very hard - intransparent - to reproduce, etc.
%
%Mention a hand-ful of papers here and there what they are looking into to signal that hey I did my research and reading
\subsection{FL Research}\label{subsection:fl_research}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fl_documents_research.png}
    \caption{Evolution of FL Publications}
    \label{fig:fl_documents_research}
\end{figure}

Figure \ref{fig:fl_documents_research} shows the exponential growth of FL documents
since 2016. (This data comes from searching for "federated learning" in article title, abstract or keywords via Scopus \cite{scopus_homepage}.)

Before we started working on FLOps we wanted to find research gaps in the fields of 
ML at the edge, specifically FL.
In total we have read and examined 47 papers in detail. 
26 papers were focused on FL. 
Additionally, we consulted several articles,
joined and participated in discussion forums,
and completed a couple of payed courses \cite{udemy_homepage}.

In this subsection we provide an overview of the current research topics in
the field of FL, including concrete examples.
We do not want to bloat this thesis by discussing each paper in great detail.
We continue by pointing out weak points and under-studied aspects.

