% research has been focused on optimizing FL algos
% comming up with new algos
% optimizing bottlenecks
%
% briefly mention the following aspects to highlight that FL is a complex topic with lots of things people are working on
% "Client-Side Local Training" - Computation, Memory, Energy, Network
% mention Security/Privacy
% https://www.notion.so/oakestra-team/Chapter-10-Local-Training-Scalability-of-FL-Systems-c0f945e2593e48ea9bdbb71c1d94d091?pvs=4
%
% Lack of papers discussing how to set-up, manage, orchestrate FL in the first place
% rarely talk how they set up their experiments
% rarely mention what they use for FL or even for ML
% very hard - intransparent - to reproduce, etc.
%
%Mention a hand-ful of papers here and there what they are looking into to signal that hey I did my research and reading
\subsection{FL Research}\label{subsection:fl_research}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{fl_documents_research.png}
    \caption{Evolution of FL Publications}
    \label{fig:fl_documents_research}
\end{figure}

Figure \ref{fig:fl_documents_research} shows the exponential growth of FL documents
since 2016. (This data comes from searching for "federated learning" in article title, abstract or keywords via Scopus \cite{scopus_homepage}.)
Note that we based the idea for this graph on \cite{thesis:tum_fl_framework_comparison}
and we used a different query with the latest available data.

Before we started working on FLOps we wanted to find research gaps in the fields of 
ML at the edge, specifically FL.
In total we have read and examined 47 papers in detail. 
26 papers were focused on FL. 
Additionally, we consulted several articles,
joined and participated in discussion forums,
and completed a couple of payed courses \cite{udemy_homepage}.
Discussing each paper in detail would heavily bloat this thesis.
We present key and meta findings instead.

During our reading we created and incrementally updated a database where we noted down
specific properties of each paper.
These properties include, one or multiple categories the paper fits in, the initial problems or challenges the authors tried to resolve,
their contributions, results, limitations, and envisioned future work.
We also noted down what ML or FL frameworks or libraries they used.
Note that these properties are based on our own subjective analysis instead of extracting them directly from the paper verbatim.

\begin{figure}[p]
    \input{tables/main_fl_research_table.tex}
\end{figure}

Table \ref{table:main_fl_research_table} depicts a subset of the FL papers we analyzed.
It shows the contributions, limitations, and future work properties that we documented.
Note that we explicitly decided to use an abbreviated format instead of verbose sentences
to optimize the limited space.
One can inspect the remaining FL papers in the appendix \ref{appendix:fl_research}.

These tables should provide a good impression of the individual papers we examined.
To get a better understanding of the research field of FL as a whole we look for patterns and trends.
We utilize the documented properties for this.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_research_categories.png}
    \caption{FL Paper Categories}
    \label{fig:fl_research_categories}
\end{figure}

Figure \ref{fig:fl_research_categories} shows the different found categories and their distribution.
The majority of our papers were focused on performance, trying out new concepts, finding best practices,
and exploring different FL architectures.
Only two papers focused on deployment and orchestration.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_research_problem_challenge.png}
    \caption{Targeted Problems \& Challenges of FL Papers}
    \label{fig:fl_research_problem_challenge}
\end{figure}

A similar trend can be seen in figure \ref{fig:fl_research_problem_challenge}.
The primary focus is on investigating new concepts or improving existing bottlenecks,
with regards to their performance, scalability, and complexity.
We point out that several papers aimed to narrow the gap between industry and research or
to make FL easier to use.
This ease of use seems to focus on improving already configured and working FL setups.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_research_contributions.png}
    \caption{FL Paper Contributions}
    \label{fig:fl_research_contributions}
\end{figure}

This is indicated by the main contributions seen in figure \cite{fig:fl_research_contributions}.
This chart is dominated by mathematical and conceptual proofs that novel
architectures and algorithms work as proposed.
Contributions do not seem to focus on improving the initial setup, deployment, and configuration processes.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_research_achieved_results.png}
    \caption{Achieved Results of FL Papers}
    \label{fig:fl_research_achieved_results}
\end{figure}

This finding is mirrored in the achieved results.
Figure \cite{fig:fl_research_achieved_results} shows that these contributions
lead to better efficiencies in terms of speed, resource utilization, training results,
and handling of heterogeneous data.
Note that we based these properties on the results and contributions the authors mentioned themselves
as well as on our own conclusions.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_research_limitations_future_work.png}
    \caption{Limitations \& Future Work of FL Papers}
    \label{fig:fl_research_limitations_future_work}
\end{figure}

Our perception is once more reflected in figure \cite{fig:fl_research_limitations_future_work}.
The focal point, if specified, is on improving privacy, security, further performance optimizations, or adding support for more ML use cases.
Even the future focus is not on optimizing accessability, usability, or the mentioned initial vital steps.

Because we assigned these properties subjectively and our sample size of papers is rather small,
we compare our findings so far with the total number of published works about FL.
We use the same method to gather the data as for \ref{fig:fl_documents_research}.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.0\textwidth]{fl_publications_compared.png}
    \caption{Evolution of FL Publications based on Keywords}
    \label{fig:fl_publications_compared}
\end{figure}


Figure \ref{fig:fl_publications_compared} shows how many works have been published in FL with
specific keywords that match our custom categories.
The global results paint a similar picture as our samples.
The most popular topics in FL are either related to privacy/security, performance,
or algorithms.
Only a very small portion of FL papers are focused on usability, automation, orchestration,
or other initial steps.

It seems that researchers assume others to have already working FL environments,
and motivate their readers to optimize them based on their findings
instead of replicating and configuring such an FL setup initially.
These tendencies can also be seen when inspecting what ML and FL frameworks and libraries
the authors mentioned they used in our examined papers.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{fl_research_ml_frameworks.png}
    \caption{Distribution of mentioned ML Frameworks in FL Papers}
    \label{fig:fl_research_ml_frameworks}
\end{figure}

Figure \cite{fig:fl_research_ml_frameworks} shows that the majority of authors
did not explicitly state what ML framework or library they used for their work.
Many researchers used Pytorch and TensorFlow.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{fl_research_fl_frameworks.png}
    \caption{Distribution of mentioned FL Frameworks in FL Papers}
    \label{fig:fl_research_fl_frameworks}
\end{figure}

Figure \cite{fig:fl_research_fl_frameworks} shows that FL researchers
very rarely mention what FL frameworks they use for their work.

It is noteworthy that it is a lot more common for authors to mention what ML 
framework they used than what FL framework they used.

Possible reasons for this might be that ML as a field is a lot older, more sophisticated,
widespread, and established.
The same applies for ML frameworks.
On the other hand, FL is a very young sub-field of ML research,
thus FL frameworks are still in their infancy.

Therefore, FL researchers might be using FL frameworks but due to the early-stage 
of the framework the researchers might not deem it important to explicitly point out that they used them.
Another possible explanation is, that FL researchers are experts in FL and
are able to setup, configure FL from the ground up by themselves.

Either way, this lack of transparency makes reproducing or extending
their work difficult if not infeasible.

This gap in FL research motivated the creation of FLOps.