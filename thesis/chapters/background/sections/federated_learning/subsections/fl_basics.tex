
\subsection{FL Basics}

Note that we assume the reader to be familiar with basic machine learning concepts.

We base the majority of this subsection on the 2022 book
'Federated Learning - A Comprehensive Overview of Methods and Applications' \cite{book:fl}.
It captures and discusses the history and progress of FL research and state-of-the-art FL techniques (up to 2022).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.9\textwidth]{classic_ml_training.png}
    \caption{Centralized ML Model Training}
    \label{fig:classic_ml_training}
\end{figure}
Figure \ref{fig:classic_ml_training} depicts the classic centralized ML model training process.
Starting from (1), where clients have their data (D) and
the server hosts the untrained (gray) ML model (M).
In (2), the clients send their data to the server.
The server can now train the model using data from both clients.
(3) depicts the final state after training.
(The pink/purple model color represents that both data sources, red and blue,
have been used during training.)
Without any policies, the client data remains on the server and is exposed
to exploitation.

As discussed in the introductory chapter, the centralized approach often leads to
privacy breaches. FL was introduced to use this lucrative sensitive data
on client devices for training ML models while keeping that data private and 
complying with laws and regulations.

Many different algorithms and strategies exist for FL.
We focus on the widely used base-case/classic FL algorithm FederatedAveraging (FedAvg)
proposed as part of the original FL paper \cite{paper:original_fl}.

\begin{figure}%[h]
    \centering
    \includegraphics[width=\textwidth]{basic_fl_intro.png}
    \caption{Basic Federated Learning}
    \label{fig:basic_fl_intro}
\end{figure}
Figure \ref{fig:basic_fl_intro} shows the basic FL training loop.
The first differences are the component names.
In FL, the server is frequently referred to as an aggregator
and clients as learners.
Note that using the terms 'server' and 'clients' in FL is still common.
We prefer to use 'aggregator' and 'learners' because it highlights that these are FL components.
This naming choice is also used in FLOps and helps with comprehension,
because FLOps uses a manifold of components, including non-FL servers and clients.
Another difference is that all components must know and possess the ML model locally.
They also need to set up their environment for training properly.

Initially, at (1), all models are untrained.
The aggregator coordinates the FL processes.
At (2), the aggregator starts the first FL training cycle by telling the learners
to start their local training.
The local training rounds (epochs) are completed at (3).
(The 'M's are now colored.)
We remind that ML models are (usually) a static lightweight set of
programming logic, including layer specification in DNNs, or training configuration,
including hyper-parameters like learning step sizes and what loss type or
activation function to use.
Model weights and biases can be seen in isolation.
A model without weights is useless because these weights and biases
are what gets trained/changed/configured in the first place and allow
the model to fulfill its intended use, like prediction, inference, or generation tasks.
These weights and biases are the major contributors to
a trained model's overall size (space utilization).
Because the model structure is static in classic ML/FL
one can transmit the weights between aggregators and learners
instead of the entire trained model.

In (4), the learners have extracted their model weights and sent them to the aggregator.
The aggregator now has access to these weights but not
to the sensitive data that was used to train them.
That is how FL can profit from sensitive data while maintaining its privacy.
Note that there are still attack vectors that allow exposing sensitive client information
by abusing this weight-based aggregation process.
We briefly discuss this and other FL security aspects later on.

In (5), the server aggregates these collected weights into
a new 'global' weight, which is applied to its own model instance.
This aggregation process is also called 'model fusion'.
Because learners can be heterogeneous and possess varying amounts of data,
some learner updates might be more impactful than others.
To respect this circumstance, learners typically also send the number
of data samples they used for training to the aggregator.
That way, the aggregator can prioritize its received updates proportionally.
Otherwise, in classic FL aggregation, the mean of the weights is used for the global model.

The result is a global model that was trained for one FL cycle.
In (6), the aggregator sends its global weights back to the learners.
The learners apply these weights to their local model instance
to make it identical to the aggregator's global model,
thus discarding their locally trained weights.
Now, the FL training loop could terminate, and the learners or servers
could use their global model copy for inference or
as depicted in (6), another FL training cycle begins.
There can be arbitrarily many FL cycles, similar to conventional training rounds
in classic ML. Sooner or later, FL training will have to stop.
Otherwise, the accuracy and loss will worsen due to overfitting.
(Assuming the available training data is finite and unchanging.)
