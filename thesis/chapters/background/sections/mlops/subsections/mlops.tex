\subsection{MLOps}

The field of ML did not employ DevOps practices for a long time and it is only now slowly getting traction.
ML differs from pure software development because it requires deep knowledge with different focal points,
like math and data-science.
Many individuals that perform ML are not trained or industry-experienced software engineers or developers.
So they might be unaware of DevOps practices or that ML can greatly benefit from them.

MLOps describes a young field that uses many best-practices and techniques from DevOps and applies them to ML.
MLOps is not a subfield of DevOps.
One can see MLOps as a specialization of DevOps, a sibling, or even a superset
because most DevOps techniques are applicable and beneficial for ML,
which requires further specialized considerations and tooling.

To understand how MLOps can benefit ML we first inspect typical ML workflows.
As an example we envision a company that wants to release a new ML-based feature to its customers.
First managers come up with the idea of utilizing ML to solve a business problem.
This problem gets evaluated and accessed.
Requirements get distilled.
We now know the problem we want to solve, but not exactly how.
ML requires data, thus, the company starts gathering data it sees fit for the task at hand.
It scouts for data sources and providers, collects data by itself and creates a custom data lake to collect its findings.

Now data engineers start preparing this data for training.
The data preprocessing includes various steps, such as cleaning the data by removing outliers, 
wrong data samples and undefined values.
Other steps transform the data to make it more suitable for training.
This includes applying normalization and standardization to
slim down the feature space to reduce the curse of dimensionality,
Other steps involve data analysis and visualization to find insightful 
patterns and ensuring that the available data is sound and useful for the business task at hand.
These data preprocessing and data acquisition steps are an iterative process.

With this data ML engineers can start designing ML models.
First model iterations are rarely ideal.
One has to train and test the model with different architectures, configurations of layers, and hyper parameters,
to find optimal values for the data and business goals.
This can be a long and complex process.

Many ML models reach this step but do not get deployed on tangible systems to provide real value.
In 2020 only 14\% of trained enterprise ML models got deployed to production in less then a week \cite{algorithmia_state_of_enterprise_ml}.
Getting an ML model to run on production environments requires entirely different skill sets
that many pure ML professionals, researchers, and hobbyist lack.

Just deploying a model is insufficient, because one has to ensure that the model works as intended for expected and unexpected use cases.
If the model is not frozen, i.e. if the model is allowed to change when deployed, or circumstances change, the model performance can degrade over time.
Thus, deployed model instances and their inference serving quality needs to be monitored.
In case of bad performance the model needs to be retrained or replaced with a better version.
Such an improved version needs to complete most fo the discussed steps again before being deployed.

This workflow combines steps from the areas of business, management, data/ml/software engineering and DevOps.
Usually, in larger organizations each step is handled by a dedicated team of experts that require working 
closely together.

On top of that, training, replicating, or understanding an ML model and its code
requires much usually untracked and unspoken background knowledge.
This includes dependencies, environments, what specific data was used for training,
what are the expected model input and output types, or if the model is production-ready.

This example demonstrates that ML code alone is insufficient to provide value from an ML model.
It requires various supporting disciplines and techniques to be usable,
including versioning, infrastructure, management, monitoring, and more.

It is easy to see that these different steps and stages have an iterative nature to them
and that the entire process is very resource and time demanding.
Therefore, ML is a prime target for DevOps techniques.

MLOps is currently heavily underutilized.

Kreuzberger et al. created a foundational piece of work \cite{paper:mlops},
where they provide an overview of MLOps and the current state of enterprise ML.
They propose first attempts of definitions and best-practices for MLOps, including 
recommended architectures, tools, and workflows.
They conclude that the field of ML is too focused on academia and improving and coming up with better ML models
instead of optimizing tangible ML in production.
Their verdict resembles ours with regards to the field of FL from section \ref{subsection:fl_research}.
