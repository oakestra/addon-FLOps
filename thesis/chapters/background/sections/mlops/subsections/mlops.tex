\subsection{MLOps}

ML differs from pure software development because it requires deep knowledge with different focal points,
such as math and data-science.
Many individuals who perform ML lack training and industry experience as software engineers or developers.
They might be unaware of DevOps practices or that ML can greatly benefit from them.

MLOps describes a young field that uses many best practices and techniques from DevOps and applies them to ML.
MLOps is not a subfield of DevOps.
MLOps is instead a specialization of DevOps, a sibling, or even a superset because most DevOps techniques
are applicable and beneficial for ML, requiring further specialized considerations and tooling.

To understand how MLOps can benefit ML, we first inspect typical ML workflows.
As an example, we envision a company that wants to release a new ML-based feature for its customers.
First, managers come up with the idea of utilizing ML to solve a business problem.
This problem gets evaluated and accessed.
Requirements get distilled.
We now know the problem we want to solve, but not precisely how.
ML requires data.
Thus, the company starts gathering data it sees fit for the task at hand.
It scouts for data sources and providers, collects data by itself, and creates a custom data lake to store its findings.

Data engineers can now start preparing this data for training.
The data preprocessing includes various steps, such as cleaning the data by removing outliers, 
wrong data samples and undefined values.
Other steps transform the data to make it more suitable for training.
This includes applying normalization and standardization to
slim down the feature space to reduce the curse of dimensionality.
Other steps involve data analysis and visualization to find insightful 
patterns and ensure that the available data is sound and useful for the business task.
These data preprocessing and data acquisition steps are an iterative process.

With this data, ML engineers can start designing ML models.
First model iterations are rarely ideal.
One has to train and test the model with different architectures, configurations of layers, and hyper-parameters
to find optimal values for the data and business goals.
This can be a long and complex process.
Many ML models reach this step but are not deployed on production systems to provide real value.
In 2020, only 14\% of trained enterprise ML models were deployed to production in less than a week \cite{algorithmia_state_of_enterprise_ml}.
Getting an ML model to run on production environments requires entirely different skill sets,
which many pure ML professionals, researchers, and hobbyists lack.

Just deploying a model is insufficient.
One has to ensure that the model works as intended for expected and unexpected use cases.
If the model is not frozen, i.e., if it is allowed to change when deployed or circumstances change, the model performance can degrade over time.
Thus, deployed model instances and their inference serving quality need monitoring.
In case of bad performance, the model needs to be retrained or replaced with a better version.
Such an improved version needs to complete most of the discussed steps again before redeployment.

This workflow combines steps from the areas of business, management, data/ml/software engineering, and operations.
Usually, in larger organizations, each step is handled by a dedicated team of experts who require working 
closely together.
In addition, training, replicating, or understanding an ML model and its code
requires extensive, usually untracked, and unspoken background knowledge.
This includes dependencies, environments, what specific data was used for training,
what are the expected model input and output types, and whether the model is production-ready.

This example demonstrates that ML code alone is insufficient to provide value from an ML model.
It requires various supporting disciplines and techniques to be usable,
including versioning, infrastructure, management, monitoring, and more.
It is easy to see that these different steps and stages are iterative
and that the entire process is very resource- and time-demanding.
Therefore, ML is a prime target for DevOps techniques.
MLOps is currently heavily underutilized.

Kreuzberger et al. wrote a foundational paper \cite{paper:mlops}
that provides an overview of MLOps and the current state of enterprise ML.
They propose the first attempts at definitions and best practices for MLOps, including 
recommended architectures, tools, and workflows.
They conclude that the field of ML is too focused on academia and improving and developing better ML models
instead of optimizing tangible ML in production.
Their verdict resembles ours with regard to the field of FL from section \ref{subsection:fl_research}.
